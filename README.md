# üß†Narrative Nexus

A simple yet powerful web app built with **FastAPI + Transformers + Vanilla JS** that lets you:

- üßπ Clean raw text or HTML content (using NLTK + BeautifulSoup)
- ‚úÇÔ∏è Summarize the cleaned text using `facebook/bart-large-cnn`
- üí¨ Analyze the **sentiment** (Positive / Negative / Neutral) of the generated summary

All in one neat, minimal dark-themed interface.

---

## üöÄ Features

- **Drag & Drop Uploads** ‚Äî upload `.txt` or `.html` files directly  
- **Instant Cleaning** ‚Äî removes HTML tags, scripts, and unwanted formatting  
- **AI-Powered Summarization** ‚Äî compresses long text into key insights  
- **Sentiment Analysis** ‚Äî interprets the emotional tone of the text  
- **FastAPI Backend** ‚Äî lightweight and async  
- **Vanilla JS Frontend** ‚Äî no frameworks, just clean HTML + JS  
- **Offline-ready** ‚Äî supports loading models locally to avoid re-downloads  

---

## üß© Project Structure

```

.
‚îú‚îÄ‚îÄ nexusnarrative/
‚îÇ   ‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI entry point
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_routes.py   # /clean-and-summarize endpoint
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_process/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleaner.py       # Uses NLTK + BeautifulSoup
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cleaned/         # Output directory
‚îÇ   ‚îî‚îÄ‚îÄ models/                  # (optional) local cached transformers models
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ index.html               # Minimal UI
‚îÇ
‚îî‚îÄ‚îÄ requirements.txt

````

---

## ‚öôÔ∏è Backend Setup (FastAPI)

### 1Ô∏è‚É£ Create and activate a virtual environment
```bash
uv venv(intstall uv using pip install uv)

source .venv/bin/activate     # on Windows: .venv\Scripts\activate
````

### 2Ô∏è‚É£ Install dependencies

```bash
puv add uvicorn transformers torch beautifulsoup4 nltk
```

> The first time you run the app, Hugging Face will download model weights (`model.safetensors`).
> These are cached locally and won‚Äôt re-download later.

### 3Ô∏è‚É£ Run the backend

```bash
uvicorn main:app --reload
```

The API should now be live at:

```
http://127.0.0.1:8000
```

Example endpoint:

```
POST /text/clean-and-summarize
```

It accepts a file upload (`.txt` or `.html`) and returns:

```json
{
  "message": "File cleaned, summarized, and analyzed successfully!",
  "preview": "First 500 chars...",
  "summary": "AI-generated summary text...",
  "sentiment": {
    "label": "POSITIVE",
    "score": 0.987
  }
}
```

---

## üíª Frontend Setup

1. Open `frontend/index.html` in your browser.
2. Make sure the API base URL in the file points to your FastAPI server:

   ```html
   <code id="api-url">http://127.0.0.1:8000</code>
   ```
3. Upload or paste some text ‚Äî and hit **‚ÄúClean, Summarize & Analyze‚Äù**.

---

## üß† How It Works

1. Uploaded text is cleaned with **NLTK** and **BeautifulSoup**
2. Cleaned text is summarized by **BART (facebook/bart-large-cnn)**
3. The summary is analyzed using **DistilBERT sentiment model**
4. The response includes:

   * Cleaned preview
   * Summarized text
   * Sentiment label + confidence score

The frontend displays all of these neatly in separate panels.

---

## üóÇ Example Output

```
Input: 3-page HTML article about global warming
‚Üí Cleaned: 4,500 words
‚Üí Summary: ‚ÄúGlobal emissions continue to rise as countries struggle to meet Paris targets...‚Äù
‚Üí Sentiment: NEGATIVE (confidence: 98.7%)
```

---

## üß∞ Optional: Local Model Storage (Offline Mode)

If you don‚Äôt want the app to download models every time:

```python
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline

model_name = "facebook/bart-large-cnn"
model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir="./app/models")
tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir="./app/models")

summarizer = pipeline("summarization", model=model, tokenizer=tokenizer)
```

Then add:
uv add "beautifulsoup4>=4.14.2" "fastapi>=0.120.0" "nltk>=3.9.2" "python-multipart>=0.0.20" "torch>=2.9.0" "transformers>=4.57.1" "uvicorn>=0.38.0" "huggingface-hub>=0.26.2"

```bash
export TRANSFORMERS_OFFLINE=1
```

---

## üßë‚Äçüíª Developer Notes

* Summarization input is truncated to **3000 chars** to fit model limits
* Sentiment input limited to **512 tokens** for performance
* Backend cleans up temporary files automatically
* Works smoothly with async FastAPI routes

---

## üèÅ Future Ideas

* [ ] Add translation support
* [ ] Multi-language sentiment detection
* [ ] Option to export cleaned + summarized text as `.txt`
* [ ] Docker support for easy deployment

---

## üß° Credits

Built with:

* [FastAPI](https://fastapi.tiangolo.com/)
* [Hugging Face Transformers](https://huggingface.co/transformers/)
* [NLTK](https://www.nltk.org/)
* [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)

> Created by Akash Kumar
(krakash2031@gmail.com)